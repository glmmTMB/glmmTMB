<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Nafis Sadat" />

<meta name="date" content="2023-04-06" />

<title>Parallel optimization using glmmTMB</title>

<script>// Hide empty <a> tag within highlighted CodeBlock for screen reader accessibility (see https://github.com/jgm/pandoc/issues/6352#issuecomment-626106786) -->
// v0.0.1
// Written by JooYoung Seo (jooyoung@psu.edu) and Atsushi Yasumoto on June 1st, 2020.

document.addEventListener('DOMContentLoaded', function() {
  const codeList = document.getElementsByClassName("sourceCode");
  for (var i = 0; i < codeList.length; i++) {
    var linkList = codeList[i].getElementsByTagName('a');
    for (var j = 0; j < linkList.length; j++) {
      if (linkList[j].innerHTML === "") {
        linkList[j].setAttribute('aria-hidden', 'true');
      }
    }
  }
});
</script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>



<style type="text/css">
  code {
    white-space: pre;
  }
  .sourceCode {
    overflow: visible;
  }
</style>
<style type="text/css" data-origin="pandoc">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Parallel optimization using glmmTMB</h1>
<h4 class="author">Nafis Sadat</h4>
<h4 class="date">2023-04-06</h4>



<p>A new, experimental feature of <code>glmmTMB</code> is the ability to parallelize the optimization process. This vignette shows an example and timing of a simple model fit with and without parallelizing across threads.</p>
<p>If your OS supports OpenMP parallelization and R was installed using OpenMP, <code>glmmTMB</code> will automatically pick up the OpenMP flags from R’s <code>Makevars</code> and compile the C++ model with OpenMP support. If the flag is not available, then the model will be compiled with serial optimization only.</p>
<p>Load packages:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a><span class="kw">library</span>(glmmTMB)</span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="kw">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb1-3"><a href="#cb1-3"></a>nt &lt;-<span class="st"> </span><span class="kw">min</span>(parallel<span class="op">::</span><span class="kw">detectCores</span>(),<span class="dv">5</span>)</span></code></pre></div>
<p>Simulate a dataset with large <code>N</code>:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1"></a>N &lt;-<span class="st"> </span><span class="fl">3e5</span></span>
<span id="cb2-2"><a href="#cb2-2"></a>xdata &lt;-<span class="st"> </span><span class="kw">rnorm</span>(N, <span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb2-3"><a href="#cb2-3"></a>ydata &lt;-<span class="st"> </span><span class="fl">0.3</span> <span class="op">+</span><span class="st"> </span><span class="fl">0.4</span><span class="op">*</span>xdata <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(N, <span class="dv">0</span>, <span class="fl">0.25</span>)</span></code></pre></div>
<p>First, we fit the model serially. We can pass the number of parallelizing process we want using the <code>parallel</code> parameter in <code>glmmTMBcontrol</code>:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1"></a><span class="kw">system.time</span>(</span>
<span id="cb3-2"><a href="#cb3-2"></a>  model1 &lt;-<span class="st"> </span><span class="kw">glmmTMB</span>(<span class="dt">formula =</span> ydata <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>xdata,</span>
<span id="cb3-3"><a href="#cb3-3"></a>                    <span class="dt">control =</span> <span class="kw">glmmTMBControl</span>(<span class="dt">parallel =</span> <span class="dv">1</span>))</span>
<span id="cb3-4"><a href="#cb3-4"></a>  )</span></code></pre></div>
<pre><code>## Warning in glmmTMB(formula = ydata ~ 1 + xdata, control =
## glmmTMBControl(parallel = 1)): use of the &#39;data&#39; argument is recommended</code></pre>
<pre><code>##    user  system elapsed 
##   3.066   0.331   3.405</code></pre>
<p>Now, we fit the same model using five threads (or as many as possible - 3 in this case):</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1"></a><span class="kw">system.time</span>(</span>
<span id="cb6-2"><a href="#cb6-2"></a>  model2 &lt;-<span class="st"> </span><span class="kw">glmmTMB</span>(<span class="dt">formula =</span> ydata <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>xdata,</span>
<span id="cb6-3"><a href="#cb6-3"></a>                    <span class="dt">control =</span> <span class="kw">glmmTMBControl</span>(<span class="dt">parallel =</span> nt))</span>
<span id="cb6-4"><a href="#cb6-4"></a>  )</span></code></pre></div>
<pre><code>## Warning in glmmTMB(formula = ydata ~ 1 + xdata, control =
## glmmTMBControl(parallel = nt)): use of the &#39;data&#39; argument is recommended</code></pre>
<pre><code>##    user  system elapsed 
##   2.814   0.312   3.129</code></pre>
<p>The speed-up is definitely more visible on models with a much larger number of observations, or in models with random effects.</p>
<p>Here’s an example where we have an IID Gaussian random effect. We first simulate the data with 200 groups (our random effect):</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1"></a>xdata &lt;-<span class="st"> </span><span class="kw">rnorm</span>(N, <span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb9-2"><a href="#cb9-2"></a>groups &lt;-<span class="st"> </span><span class="dv">200</span></span>
<span id="cb9-3"><a href="#cb9-3"></a>data_use &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">obs =</span> <span class="dv">1</span><span class="op">:</span>N)</span>
<span id="cb9-4"><a href="#cb9-4"></a>data_use &lt;-<span class="st"> </span><span class="kw">within</span>(data_use,</span>
<span id="cb9-5"><a href="#cb9-5"></a>{</span>
<span id="cb9-6"><a href="#cb9-6"></a>  </span>
<span id="cb9-7"><a href="#cb9-7"></a>  group_var &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="kw">seq</span>(groups), <span class="dt">times =</span> <span class="kw">nrow</span>(data_use) <span class="op">/</span><span class="st"> </span>groups)</span>
<span id="cb9-8"><a href="#cb9-8"></a>  group_intercept &lt;-<span class="st"> </span><span class="kw">rnorm</span>(groups, <span class="dv">0</span>, <span class="fl">0.1</span>)[group_var]</span>
<span id="cb9-9"><a href="#cb9-9"></a>  xdata &lt;-<span class="st"> </span>xdata</span>
<span id="cb9-10"><a href="#cb9-10"></a>  ydata &lt;-<span class="st"> </span><span class="fl">0.3</span> <span class="op">+</span><span class="st"> </span>group_intercept <span class="op">+</span><span class="st"> </span><span class="fl">0.5</span><span class="op">*</span>xdata <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(N, <span class="dv">0</span>, <span class="fl">0.25</span>)</span>
<span id="cb9-11"><a href="#cb9-11"></a>})</span></code></pre></div>
<p>We fit the random effect model, first with a single thread:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1"></a>(t_serial &lt;-<span class="st"> </span><span class="kw">system.time</span>(</span>
<span id="cb10-2"><a href="#cb10-2"></a>  model3 &lt;-<span class="st"> </span><span class="kw">glmmTMB</span>(<span class="dt">formula =</span> ydata <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>xdata <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>group_var), <span class="dt">data =</span> data_use, <span class="dt">control =</span> <span class="kw">glmmTMBControl</span>(<span class="dt">parallel =</span> <span class="dv">1</span>))</span>
<span id="cb10-3"><a href="#cb10-3"></a> )</span>
<span id="cb10-4"><a href="#cb10-4"></a>)</span></code></pre></div>
<pre><code>##    user  system elapsed 
##  17.905   1.465  19.385</code></pre>
<p>Now we fit the same model, but using 3 threads. The speed-up is more noticeable with this model.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1"></a>(t_parallel &lt;-<span class="st"> </span><span class="kw">system.time</span>(</span>
<span id="cb12-2"><a href="#cb12-2"></a>     <span class="kw">update</span>(model3,  <span class="dt">control =</span> <span class="kw">glmmTMBControl</span>(<span class="dt">parallel =</span> nt))</span>
<span id="cb12-3"><a href="#cb12-3"></a> )</span>
<span id="cb12-4"><a href="#cb12-4"></a>)</span></code></pre></div>
<pre><code>##    user  system elapsed 
##  18.228   1.546  19.788</code></pre>
<div id="notes-on-openmp-support" class="section level2">
<h2>Notes on OpenMP support</h2>
<p>From <a href="https://cran.r-project.org/doc/manuals/r-devel/R-exts.html#OpenMP-support">Writing R Extensions</a>:</p>
<blockquote>
<p>Apple builds of clang on macOS currently have no OpenMP support, but CRAN binary packages are built with a clang-based toolchain which supports OpenMP. <a href="https://www.openmp.org/resources/openmp-compilers-tools/" class="uri">https://www.openmp.org/resources/openmp-compilers-tools/</a> gives some idea of what compilers support what versions.</p>
</blockquote>
<blockquote>
<p>The performance of OpenMP varies substantially between platforms. The Windows implementation has substantial overheads, so is only beneficial if quite substantial tasks are run in parallel. Also, on Windows new threads are started with the default FPU control word, so computations done on OpenMP threads will not make use of extended-precision arithmetic which is the default for the main process. ## System information</p>
</blockquote>
<p>This report was built using 3 parallel threads (on a machine with a total of 3 cores)</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1"></a><span class="kw">print</span>(<span class="kw">sessionInfo</span>(), <span class="dt">locale=</span><span class="ot">FALSE</span>)</span></code></pre></div>
<pre><code>## R version 4.2.3 (2023-03-15)
## Platform: x86_64-apple-darwin17.0 (64-bit)
## Running under: macOS Big Sur ... 10.16
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib
## 
## attached base packages:
## [1] grid      stats     graphics  grDevices utils     datasets  methods  
## [8] base     
## 
## other attached packages:
##  [1] png_0.1-8          ggplot2_3.4.2      lattice_0.20-45    reshape2_1.4.4    
##  [5] coda_0.19-4        mvabund_4.2.1      TMB_1.9.3          MASS_7.3-58.2     
##  [9] glmmTMB_1.1.7.9000 knitr_1.42        
## 
## loaded via a namespace (and not attached):
##  [1] sass_0.4.5                jsonlite_1.8.4           
##  [3] splines_4.2.3             R.utils_2.12.2           
##  [5] bslib_0.4.2               statmod_1.5.0            
##  [7] stats4_4.2.3              highr_0.10               
##  [9] yaml_2.3.7                numDeriv_2016.8-1.1      
## [11] pillar_1.9.0              glue_1.6.2               
## [13] bbmle_1.0.25              digest_0.6.31            
## [15] minqa_1.2.5               colorspace_2.1-0         
## [17] sandwich_3.0-2            pkgdown.extras_0.0.0-9003
## [19] htmltools_0.5.5           Matrix_1.5-3             
## [21] R.oo_1.25.0               plyr_1.8.8               
## [23] pkgconfig_2.0.3           xtable_1.8-4             
## [25] mvtnorm_1.1-3             scales_1.2.1             
## [27] processx_3.8.0            lme4_1.1-32              
## [29] emmeans_1.8.5             tibble_3.2.1             
## [31] generics_0.1.3            farver_2.1.1             
## [33] TH.data_1.1-1             cachem_1.0.7             
## [35] withr_2.5.0               cli_3.6.1                
## [37] survival_3.5-3            magrittr_2.0.3           
## [39] crayon_1.5.2              memoise_2.0.1            
## [41] estimability_1.4.1        evaluate_0.20            
## [43] ps_1.7.4                  R.methodsS3_1.8.2        
## [45] fs_1.6.1                  fansi_1.0.4              
## [47] R.cache_0.16.0            nlme_3.1-162             
## [49] pkgbuild_1.4.0            R.rsp_0.45.0             
## [51] tools_4.2.3               prettyunits_1.1.1        
## [53] lifecycle_1.0.3           multcomp_1.4-23          
## [55] stringr_1.5.0             munsell_0.5.0            
## [57] callr_3.7.3               compiler_4.2.3           
## [59] pkgdown_2.0.7             jquerylib_0.1.4          
## [61] rlang_1.1.0               nloptr_2.0.3             
## [63] tweedie_2.3.5             labeling_0.4.2           
## [65] rmarkdown_2.21            boot_1.3-28.1            
## [67] gtable_0.3.3              codetools_0.2-19         
## [69] R6_2.5.1                  zoo_1.8-11               
## [71] bdsmatrix_1.3-6           dplyr_1.1.1              
## [73] fastmap_1.1.1             utf8_1.2.3               
## [75] rprojroot_2.0.3           desc_1.4.2               
## [77] stringi_1.7.12            parallel_4.2.3           
## [79] Rcpp_1.0.10               vctrs_0.6.1              
## [81] tidyselect_1.2.0          xfun_0.38</code></pre>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
