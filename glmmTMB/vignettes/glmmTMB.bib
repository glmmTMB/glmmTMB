
@Book{Bolker2008,
  author =	 {Benjamin M. Bolker},
  title = 	 {Ecological Models and Data in R},
  publisher = 	 {Princeton University Press},
  year = 	 {2008},
  address =	 {Princeton, NJ}
}


@article{roulinbersier_2007,
title = {Nestling barn owls beg more
     intensely in the presence of their mother than in the presence of
     their father},
author = {Roulin, A. and L. Bersier},
year = {2007},
journal= {Animal Behaviour},
volume= {74},
pages={1099-1106},
doi = {10.1016/j.anbehav.2007.01.027}
}

@book{zuur_mixed_2009,
	edition = {1},
	title = {Mixed Effects Models and Extensions in Ecology with R},
	isbn = {0387874577},
	publisher = {Springer},
	author = {Zuur, Alain F. and Ieno, Elena N. and Walker, Neil J. and Saveliev, Anatoly A. and Smith, Graham M.},
	month = mar,
	year = {2009}
}

@ARTICLE{Fournieretal11,
   author = {David A. Fournier and Hans J. Skaug and Johnoel Ancheta and Jim Ianellid and Arni Magnusson
             and Mark Maunder and Anders Nielsen and John Sibert},
   year =  {2011},
   title = {AD Model Builder: using automatic differentiation for statistical
            inference of highly parameterized complex nonlinear models},
   journal = {Optimization Methods \& Software},
   volume = {00},
   number = {0},
   pages = {1â€“17}
}



@article{bolker_generalized_2009,
	title = {Generalized linear mixed models: a practical guide for ecology and evolution},
	volume = {24},
	issn = {0169-5347},
	shorttitle = {Generalized linear mixed models},
	doi = {10.1016/j.tree.2008.10.008},
	abstract = {How should ecologists and evolutionary biologists analyze nonnormal data that involve random effects? Nonnormal data such as counts or proportions often defy classical statistical procedures. Generalized linear mixed models {(GLMMs)} provide a more flexible approach for analyzing nonnormal data when random effects are present. The explosion of research on {GLMMs} in the last decade has generated considerable uncertainty for practitioners in ecology and evolution. Despite the availability of accurate techniques for estimating {GLMM} parameters in simple cases, complex {GLMMs} are challenging to fit and statistical inference such as hypothesis testing remains difficult. We review the use (and misuse) of {GLMMs} in ecology and evolution, discuss estimation and inference and summarize [`]best-practice' data analysis procedures for scientists facing this challenge.},
	journal = {Trends in Ecology \& Evolution},
	author = {Bolker, Benjamin M. and Brooks, Mollie E. and Clark, Connie J. and Geange, Shane W. and Poulsen, John R. and Stevens, M. Henry H. and White, {Jada-Simone} S.},
	year = {2009},
	pages = {127--135}
}

@InCollection{bolker_glmm_2014,
  author =	 {Benjamin M. Bolker},
  editor =	 {Fox, Gordon A. and Negrete-Yankelevich, Simoneta and Sosa, Vinicio J.},
  booktitle = 	 {Ecological Statistics: Contemporary theory and application},
  title = 	 {Linear and Generalized Linear Mixed Models},
  publisher = 	 {Oxford University Press},
  year = 	 {2015},
  chapter =      {13},
  isbn = {978-0-19-967255-4}
}

@book{hardin_generalized_2007,
	title = {Generalized linear models and extensions},
	isbn = {9781597180146},
	publisher = {Stata Press},
	author = {Hardin, James William and Hilbe, Joseph},
	month = feb,
	year = {2007}
}


@book{zuur_beginners_2013,
	title = {A Beginner's Guide to {GLM} and {GLMM} with {R}: A Frequentist and {Bayesian} Perspective for Ecologists},
	isbn = {978-0-9571741-3-9},
	shorttitle = {A {Beginner}'s {Guide} to {GLM} and {GLMM} with {R}},
	publisher = {Highland Statistics Ltd},
	author = {Zuur, Alain F. and Hilbe, Joseph M. and Leno, Elena N.},
	month = may,
	year = {2013}
}

@book{millar_maximum_2011,
	title = {Maximum Likelihood Estimation and Inference: With Examples in R, {SAS} and {ADMB}},
	isbn = {9781119977711},
	shorttitle = {Maximum Likelihood Estimation and Inference},
	abstract = {This book takes a fresh look at the popular and well-established method of maximum likelihood for statistical estimation and inference. It begins with an intuitive introduction to the concepts and background of likelihood, and moves through to the latest developments in maximum likelihood methodology, including general latent variable models and new material for the practical implementation of integrated likelihood using the free {ADMB} software. Fundamental issues of statistical inference are also examined, with a presentation of some of the philosophical debates underlying the choice of statistical {paradigm.Key} features: Provides an accessible introduction to pragmatic maximum likelihood {modelling.Covers} more advanced topics, including general forms of latent variable models (including non-linear and non-normal mixed-effects and state-space models) and the use of maximum likelihood variants, such as estimating equations, conditional likelihood, restricted likelihood and integrated {likelihood.Adopts} a practical approach, with a focus on providing the relevant tools required by researchers and practitioners who collect and analyze real {data.Presents} numerous examples and case studies across a wide range of applications including medicine, biology and {ecology.Features} applications from a range of disciplines, with implementation in R, {SAS} and/or {ADMB.Provides} all program code and software extensions on a supporting {website.Confines} supporting theory to the final chapters to maintain a readable and pragmatic focus of the preceding chapters. This book is not just an accessible and practical text about maximum likelihood, it is a comprehensive guide to modern maximum likelihood estimation and inference. It will be of interest to readers of all levels, from novice to expert. It will be of great benefit to researchers, and to students of statistics from senior undergraduate to graduate level. For use as a course text, exercises are provided at the end of each chapter.},
	language = {en},
	publisher = {John Wiley \& Sons},
	author = {Millar, Russell B.},
	month = jul,
	year = {2011},
	keywords = {Computers / Mathematical \& Statistical Software, Mathematics / Probability \& Statistics / General}
}


@article{niku2019gllvm,
	title = {gllvm: {Fast} analysis of multivariate abundance data with generalized linear latent variable models in {R}},
	volume = {10},
	issn = {2041-210X},
	shorttitle = {gllvm},
	doi = {10.1111/2041-210X.13303},
	abstract = {There has been rapid development in tools for multivariate analysis based on fully specified statistical models or 'joint models'. One approach attracting a lot of attention is generalized linear latent variable models (GLLVMs). However, software for fitting these models is typically slow and not practical for large datasets. The R package gllvm offers relatively fast methods to fit GLLVMs via maximum likelihood, along with tools for model checking, visualization and inference. The main advantage of the package over other implementations is speed, for example, being two orders of magnitude faster, and capable of handling thousands of response variables. These advances come from using variational approximations to simplify the likelihood expression to be maximized, automatic differentiation software for model-fitting (via the TMB package) and careful choice of initial values for parameters. Examples are used to illustrate the main features and functionality of the package, such as constrained or unconstrained ordination, including functional traits in 'fourth corner' models, and (if the number of environmental coefficients is not large) make inferences about environmental associations.},
	language = {en},
	number = {12},
	urldate = {2021-03-17},
	journal = {Methods in Ecology and Evolution},
	author = {Niku, Jenni and Hui, Francis K. C. and Taskinen, Sara and Warton, David I.},
	year = {2019},
	keywords = {abundance data, generalized linear latent variable models, high-dimensional data, joint modelling, maximum likelihood, multivariate analysis, ordination, species interactions},
	pages = {2173--2182}
}

@article{hui2015model,
	title={Model-based approaches to unconstrained ordination},
	volume={6},
	doi = {10.1111/2041-210X.12236},
	abstract = {Summary
1. Unconstrained ordination is commonly used in ecology to visualize multivariate data, in particular, to visualize
themain trends between different sites in terms of their species composition or relative abundance.
2. Methods of unconstrained ordination currently used, such as non-metric multidimensional scaling, are algorithm-
based techniques developed and implemented without directly accommodating the statistical properties of
the data at hand. Failure to account for these key data properties can lead to misleading results.
3. A model-based approach to unconstrained ordination can address this issue, and in this study, two types of
models for ordination are proposed based on finite mixture models and latent variable models. Each method is
capable of handling different data types and different forms of species response to latent gradients. Further
strengths of the models are demonstrated via example and simulation.
4. Advantages of model-based approaches to ordination include the following: residual analysis tools for checking
assumptions to ensure the fitted model is appropriate for the data; model selection tools to choose the most
appropriate model for ordination; methods for formal statistical inference to draw conclusions from the ordination;
and improved efficiency, that is model-based ordination better recovers true relationships between sites,
when used appropriately.},
	language = {en},
	number={4},
	urldate = {2021-03-23},
	journal={Methods in Ecology and Evolution},
	author={Hui, Francis KC and Taskinen, Sara and Pledger, Shirley and Foster, Scott D and Warton, David I},
	year={2015},
	keywords = {correspondence analysis, latent variable model, mixture model, multivariate analysis,
non-metric multidimensional scaling},
  pages={399--411}
}


@article{chungNondegenerate2013,
	title = {A {Nondegenerate} {Penalized} {Likelihood} {Estimator} for {Variance} {Parameters} in {Multilevel} {Models}},
	volume = {78},
	issn = {0033-3123, 1860-0980},
	url = {http://link.springer.com/article/10.1007/s11336-013-9328-2},
	doi = {10.1007/s11336-013-9328-2},
	abstract = {Group-level variance estimates of zero often arise when fitting multilevel or hierarchical linear models, especially when the number of groups is small. For situations where zero variances are implausible a priori, we propose a maximum penalized likelihood approach to avoid such boundary estimates. This approach is equivalent to estimating variance parameters by their posterior mode, given a weakly informative prior distribution. By choosing the penalty from the log-gamma family with shape parameter greater than 1, we ensure that the estimated variance will be positive. We suggest a default log-gamma(2,Î») penalty with Î»â†’0, which ensures that the maximum penalized likelihood estimate is approximately one standard error from zero when the maximum likelihood estimate is zero, thus remaining consistent with the data while being nondegenerate. We also show that the maximum penalized likelihood estimator with this default penalty is a good approximation to the posterior median obtained under a noninformative prior. Our default method provides better estimates of model parameters and standard errors than the maximum likelihood or the restricted maximum likelihood estimators. The log-gamma family can also be used to convey substantive prior information. In either caseâ€”pure penalization or prior informationâ€”our recommended procedure gives nondegenerate estimates and in the limit coincides with maximum likelihood as the number of groups increases.},
	language = {en},
	number = {4},
	urldate = {2015-07-15},
	journal = {Psychometrika},
	author = {Chung, Yeojin and Rabe-Hesketh, Sophia and Dorie, Vincent and Gelman, Andrew and Liu, Jingchen},
	month = mar,
	year = {2013},
	keywords = {Psychometrics, Mixed Model, Multilevel model, penalized likelihood, Statistical Theory and Methods, Assessment, Testing and Evaluation, Bayes modal estimation, hierarchical linear model, Statistics for Social Science, Behavorial Science, Education, Public Policy, and Law, variance estimation, weakly informative prior},
	pages = {685--709}
}

@mastersthesis{schackeKronecker2004,
  title = {On the {{Kronecker}} Product},
  author = {Sch{\"a}cke, Kathrin},
  year = {2004},
  urldate = {2023-08-23},
  abstract = {In this paper, we review basic properties of the Kronecker product, and give an overview of its history and applications. We then move on to introducing the symmetric Kronecker product, and we derive se eral of its properties. Furthermore, we show its application in finding search directions in semidefinite programming.},
  school = {University of Waterloo},
  url = {https://www.math.uwaterloo.ca/~hwolkowi/henry/reports/kronthesisschaecke04.pdf}
}


@article{madarDirect2015b,
	title = {Direct formulation to {Cholesky} decomposition of a general nonsingular correlation matrix},
	volume = {103},
	issn = {0167-7152},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4455603/},
	doi = {10.1016/j.spl.2015.03.014},
	abstract = {We present two novel and explicit parametrizations of Cholesky factor of a nonsingular correlation matrix. One that uses semi-partial correlation coefficients, and a second that utilizes differences between the successive ratios of two determinants. To each, we offer a useful application.},
	urldate = {2023-08-25},
	journal = {Statistics \& probability letters},
	author = {Madar, Vered},
	month = aug,
	year = {2015},
	pmid = {26052169},
	pmcid = {PMC4455603},
	pages = {142--147}
}

@article{bannerUse2020,
  title = {The Use of {Bayesian} Priors in Ecology: The Good, the Bad and the Not Great},
  shorttitle = {The Use of {{Bayesian}} Priors in {{Ecology}}},
  author = {Banner, Katharine M. and Irvine, Kathryn M. and Rodhouse, Thomas J.},
  year = {2020},
  journal = {Methods in Ecology and Evolution},
  volume = {11},
  number = {8},
  pages = {882--889},
  issn = {2041-210X},
  doi = {10.1111/2041-210X.13407},
  urldate = {2023-05-19},
  abstract = {Bayesian data analysis (BDA) is a powerful tool for making inference from ecological data, but its full potential has yet to be realized. Despite a generally positive trajectory in research surrounding model development and assessment, far too little attention has been given to prior specification. Default priors, a sub-class of non-informative prior distributions that are often chosen without critical thought or evaluation, are commonly used in practice. We believe the fear of being too `subjective' has prevented many researchers from using any prior information in their analyses despite the fact that defending prior choice (informative or not) promotes good statistical practice. In this commentary, we provide an overview of how BDA is currently being used in a random sample of articles, discuss implications for inference if current bad practices continue, and highlight sub-fields where knowledge about the system has improved inference and promoted good statistical practices through the careful and justified use of informative priors. We hope to inspire a renewed discussion about the use of Bayesian priors in Ecology with particular attention paid to specification and justification. We also emphasize that all priors are the result of a subjective choice, and should be discussed in that way.},
  langid = {english},
  keywords = {Bayesian hierarchical models,good statistical practice,sensitivity analysis,subjective priors}
}

@inproceedings{sarmaPrior2020,
  title = {Prior Setting in Practice: Strategies and Rationales Used in Choosing Prior Distributions for {Bayesian} Analysis},
  shorttitle = {Prior {{Setting}} in {{Practice}}},
  booktitle = {Proceedings of the 2020 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Sarma, Abhraneel and Kay, Matthew},
  year = {2020},
  month = apr,
  series = {{{CHI}} '20},
  pages = {1--12},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3313831.3376377},
  urldate = {2023-05-27},
  abstract = {Bayesian statistical analysis is steadily growing in popularity and use. Choosing priors is an integral part of Bayesian inference. While there exist extensive normative recommendations for prior setting, little is known about how priors are chosen in practice. We conducted a survey (N = 50) and interviews (N = 9) where we used interactive visualizations to elicit prior distributions from researchers experienced withBayesian statistics and asked them for rationales for those priors. We found that participants' experience and philosophy influence how much and what information they are willing to incorporate into their priors, manifesting as different levels of informativeness and skepticism. We also identified three broad strategies participants use to set their priors: centrality matching, interval matching, and visual mass allocation. We discovered that participants' understanding of the notion of 'weakly informative priors"-a commonly-recommended normative approach to prior setting-manifests very differently across participants. Our results have implications both for how to develop prior setting recommendations and how to design tools to elicit priors in Bayesian analysis.},
  isbn = {978-1-4503-6708-0},
  keywords = {bayesian inference,descriptive analysis,prior distributions}
}

@misc{mcgillycuddyParsimoniously2024,
  title = {Parsimoniously Fitting Large Multivariate Random Effects in {glmmTMB}},
  author = {Maeve McGillycuddy and David I. Warton and Gordana Popovic and Benjamin M. Bolker},
    institution = {{arXiv}},
  url = {https://arxiv.org/abs/2411.04411}
}
